Common
A set of components and interfaces for distributed filesystems and general I/O (serialization, Java RPC, persistent data structures).

Avro
A serialization system for efficient, cross-language RPC and persistent data storage.

MapReduce
A distributed data processing model and execution environment that runs on large clusters of commodity machines.

HDFS
A distributed filesystem that runs on large clusters of commodity machines.

Pig
A data flow language and execution environment for exploring very large datasets.Pig runs on HDFS and MapReduce clusters.

Hive
A distributed data warehouse. Hive manages data stored in HDFS and provides a query language based on SQL (and which is translated by the runtime engine to MapReduce jobs) for querying the data.

HBase
A distributed, column-oriented database. HBase uses HDFS for its underlying storage, and supports both batch-style computations using MapReduce and point queries (random reads).

ZooKeeper
A distributed, highly available coordination service. ZooKeeper provides primitives such as distributed locks that can be used for building distributed applications.

Sqoop
A tool for efficient bulk transfer of data between structured data stores (such asrelational databases) and HDFS.

Oozie
A service for running and scheduling workflows of Hadoop jobs (including Map-Reduce, Pig, Hive, and Sqoop jobs).


-- Hadoop Commands --
hadoop namenode -format
hdfs dfs -ls /
move local to hadoop fs - "bin/hadoop fs -get /hdfs/source/path /localfs/destination/path"
copy to local from hadoop fs - "bin/hadoop fs -copyToLocal /hdfs/source/path /localfs/destination/path"
remove directory from hdfs - hadoop fs -rm -r -skipTrash /path_to_file/file_name
content of file in hdfs - hdfs dfs -cat /output/*
Access the logs - http://localhost:50030/jobtracker.jsp

